{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Evaluating Multiple Models in a Python 2 Notebook\n\n##  Introduction\n\nThe purpose of this example is to compare the performance of machine learning models within a Jupyter notebook. We will use the classic 1974 *Motor Trend* car road tests (`mtcars`) dataset to fit and evaluate three models:\n1. A linear model using all variables\n1. A linear model after variable selection\n1. A Gradient Boosting Machine (GBM) model \n\nThis is a lightly-modified version of a [notebook](https://gallery.cortanaintelligence.com/Notebook/Evaluating-Multiple-Models-6) originally created by a Microsoft employee for distribution on the [Cortana Intelligence Gallery](https://gallery.cortanaintelligence.com/). [Python 3 and R versions](https://notebooks.azure.com/library/eSJDgAFMXAY) of this notebook are also available on Azure Notebooks.\n\n## Outline\n\n- [Introduction](#Introduction)\n- [Prepare Data](#Prepare-Data)\n- [Fit Models](#Fit-Models)\n   - [Linear Model](#Linear-Model)\n   - [Linear Model with Feature Selection](#Linear-Model-with-Feature-Selection)\n   - [Gradient Boosting Machine Regression Model](#Gradient-Boosting-Machine-Regression-Model)\n- [Conclusion](#Conclusion)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare Data\n\nWe'll start by loading the `mtcars` sample dataset and displaying its description:"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "!pip install pydataset --disable-pip-version-check -q # install a Python package containing the dataset\nimport pydataset\nfrom pydataset import data\ndf = data('mtcars')\ndata('mtcars', show_doc=True)",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "mtcars\n\nPyDataset Documentation (adopted from R Documentation. The displayed examples are in R)\n\n## Motor Trend Car Road Tests\n\n### Description\n\nThe data was extracted from the 1974 _Motor Trend_ US magazine, and comprises\nfuel consumption and 10 aspects of automobile design and performance for 32\nautomobiles (1973-74 models).\n\n### Usage\n\n    \n    \n    mtcars\n\n### Format\n\nA data frame with 32 observations on 11 variables.\n\n[, 1]\n\nmpg\n\nMiles/(US) gallon\n\n[, 2]\n\ncyl\n\nNumber of cylinders\n\n[, 3]\n\ndisp\n\nDisplacement (cu.in.)\n\n[, 4]\n\nhp\n\nGross horsepower\n\n[, 5]\n\ndrat\n\nRear axle ratio\n\n[, 6]\n\nwt\n\nWeight (lb/1000)\n\n[, 7]\n\nqsec\n\n1/4 mile time\n\n[, 8]\n\nvs\n\nV/S\n\n[, 9]\n\nam\n\nTransmission (0 = automatic, 1 = manual)\n\n[,10]\n\ngear\n\nNumber of forward gears\n\n[,11]\n\ncarb\n\nNumber of carburetors\n\n### Source\n\nHenderson and Velleman (1981), Building multiple regression models\ninteractively. _Biometrics_, **37**, 391-411\\.\n\n### Examples\n\n    \n    \n    require(graphics)\n    pairs(mtcars, main = \"mtcars data\")\n    coplot(mpg ~ disp | as.factor(cyl), data = mtcars,\n           panel = panel.smooth, rows = 1)\n    \n\n\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also quickly examine the distribution of values and first few rows of the dataset:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.describe()",
      "execution_count": 5,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cyl</th>\n      <th>disp</th>\n      <th>hp</th>\n      <th>drat</th>\n      <th>wt</th>\n      <th>qsec</th>\n      <th>vs</th>\n      <th>am</th>\n      <th>gear</th>\n      <th>carb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.000000</td>\n      <td>32.0000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>20.090625</td>\n      <td>6.187500</td>\n      <td>230.721875</td>\n      <td>146.687500</td>\n      <td>3.596563</td>\n      <td>3.217250</td>\n      <td>17.848750</td>\n      <td>0.437500</td>\n      <td>0.406250</td>\n      <td>3.687500</td>\n      <td>2.8125</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.026948</td>\n      <td>1.785922</td>\n      <td>123.938694</td>\n      <td>68.562868</td>\n      <td>0.534679</td>\n      <td>0.978457</td>\n      <td>1.786943</td>\n      <td>0.504016</td>\n      <td>0.498991</td>\n      <td>0.737804</td>\n      <td>1.6152</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10.400000</td>\n      <td>4.000000</td>\n      <td>71.100000</td>\n      <td>52.000000</td>\n      <td>2.760000</td>\n      <td>1.513000</td>\n      <td>14.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>15.425000</td>\n      <td>4.000000</td>\n      <td>120.825000</td>\n      <td>96.500000</td>\n      <td>3.080000</td>\n      <td>2.581250</td>\n      <td>16.892500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>2.0000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>19.200000</td>\n      <td>6.000000</td>\n      <td>196.300000</td>\n      <td>123.000000</td>\n      <td>3.695000</td>\n      <td>3.325000</td>\n      <td>17.710000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>2.0000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>22.800000</td>\n      <td>8.000000</td>\n      <td>326.000000</td>\n      <td>180.000000</td>\n      <td>3.920000</td>\n      <td>3.610000</td>\n      <td>18.900000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>4.0000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>33.900000</td>\n      <td>8.000000</td>\n      <td>472.000000</td>\n      <td>335.000000</td>\n      <td>4.930000</td>\n      <td>5.424000</td>\n      <td>22.900000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>8.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "             mpg        cyl        disp          hp       drat         wt  \\\ncount  32.000000  32.000000   32.000000   32.000000  32.000000  32.000000   \nmean   20.090625   6.187500  230.721875  146.687500   3.596563   3.217250   \nstd     6.026948   1.785922  123.938694   68.562868   0.534679   0.978457   \nmin    10.400000   4.000000   71.100000   52.000000   2.760000   1.513000   \n25%    15.425000   4.000000  120.825000   96.500000   3.080000   2.581250   \n50%    19.200000   6.000000  196.300000  123.000000   3.695000   3.325000   \n75%    22.800000   8.000000  326.000000  180.000000   3.920000   3.610000   \nmax    33.900000   8.000000  472.000000  335.000000   4.930000   5.424000   \n\n            qsec         vs         am       gear     carb  \ncount  32.000000  32.000000  32.000000  32.000000  32.0000  \nmean   17.848750   0.437500   0.406250   3.687500   2.8125  \nstd     1.786943   0.504016   0.498991   0.737804   1.6152  \nmin    14.500000   0.000000   0.000000   3.000000   1.0000  \n25%    16.892500   0.000000   0.000000   3.000000   2.0000  \n50%    17.710000   0.000000   0.000000   4.000000   2.0000  \n75%    18.900000   1.000000   1.000000   4.000000   4.0000  \nmax    22.900000   1.000000   1.000000   5.000000   8.0000  "
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 6,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cyl</th>\n      <th>disp</th>\n      <th>hp</th>\n      <th>drat</th>\n      <th>wt</th>\n      <th>qsec</th>\n      <th>vs</th>\n      <th>am</th>\n      <th>gear</th>\n      <th>carb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Mazda RX4</th>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.620</td>\n      <td>16.46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Mazda RX4 Wag</th>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.875</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Datsun 710</th>\n      <td>22.8</td>\n      <td>4</td>\n      <td>108.0</td>\n      <td>93</td>\n      <td>3.85</td>\n      <td>2.320</td>\n      <td>18.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Hornet 4 Drive</th>\n      <td>21.4</td>\n      <td>6</td>\n      <td>258.0</td>\n      <td>110</td>\n      <td>3.08</td>\n      <td>3.215</td>\n      <td>19.44</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Hornet Sportabout</th>\n      <td>18.7</td>\n      <td>8</td>\n      <td>360.0</td>\n      <td>175</td>\n      <td>3.15</td>\n      <td>3.440</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\nMazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \nMazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \nDatsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \nHornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \nHornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n\n                   carb  \nMazda RX4             4  \nMazda RX4 Wag         4  \nDatsun 710            1  \nHornet 4 Drive        1  \nHornet Sportabout     2  "
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The goal for the machine learning models in this tutorial will be to predict each car's gas mileage (`mpg`) from the car's other features.\n\nWe will split the records into training and test datasets: each model will be fitted using the training data, and evaluated using the withheld test data."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.cross_validation import train_test_split\n\n# split the dataset into features available for prediction (X) and value to predict (y)\ny = df['mpg'].values\nX = df.drop('mpg', 1).values\nfeature_names = df.drop('mpg', 1).columns\n\n# save 30% of the records for the test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\nX_train.shape",
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "text/plain": "(22, 10)"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As you can see from the description above, the number of predictive features available in this dataset (10) is comparable to the number of records (22). Such conditions tend to produce overfitted models that give exceptional predictions on their own training data, but poor predictions on the withheld test data. We will see an example of an overfitted model below."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Fit Models\n### Linear Model\nThe following lines of code fit a linear model (without regularization) using all of the original features:"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(X_train, y_train)",
      "execution_count": 8,
      "outputs": [
        {
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Below, we print the R-squared value for the true vs. predicted `mpg` values in the *training* set. We also show the fitted coefficients for different features."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.metrics import r2_score\n\n# print R^2 for the training set\nprint('The R-squared value for the training set is: {:0.4f}'.format(r2_score(y_train, lm.predict(X_train))))\n\n# print intercept and coefficients\nparam_df = pd.DataFrame({\"Coefficient\": [lm.intercept_] + list(lm.coef_),\n                         \"Feature\": ['intercept'] + list(feature_names)})\nparam_df[['Feature', 'Coefficient']]",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The R-squared value for the training set is: 0.8932\n"
        },
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>intercept</td>\n      <td>-26.404570</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cyl</td>\n      <td>0.694624</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disp</td>\n      <td>0.021889</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp</td>\n      <td>-0.013067</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>drat</td>\n      <td>1.363191</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>wt</td>\n      <td>-5.000644</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>qsec</td>\n      <td>2.633275</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vs</td>\n      <td>0.206116</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>am</td>\n      <td>5.219608</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>gear</td>\n      <td>-0.096164</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>carb</td>\n      <td>0.421154</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      Feature  Coefficient\n0   intercept   -26.404570\n1         cyl     0.694624\n2        disp     0.021889\n3          hp    -0.013067\n4        drat     1.363191\n5          wt    -5.000644\n6        qsec     2.633275\n7          vs     0.206116\n8          am     5.219608\n9        gear    -0.096164\n10       carb     0.421154"
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Notice that the model performs very well on the training data to which it was fitted. (Predictions of the model account for 89% of the variance in `mpg` values.) Some of the feature coefficients may reflect our intuition: for example, heavy cars tend to have worse gas mileage ($\\beta_{\\textrm{wt}} = -5.0$), and cars with manual transmissions tend to have better gas mileage ($\\beta_{\\textrm{am}} = 5.2$).\n\nNow, let's check the model's performance on the test dataset:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np\n\npredicted = lm.predict(X_test)\n\nr_squared = r2_score(y_test, predicted)\nmae = np.mean(abs(predicted - y_test))\nrmse = np.sqrt(np.mean((predicted - y_test)**2))\nrae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\nrse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n\n# Create a data frame for storing results from each model\nsummary_df = pd.DataFrame(index = ['R-squared', 'Mean Absolute Error', 'Root Mean Squared Error',\n                                   'Relative Absolute Error', 'Relative Squared Error'])\nsummary_df['Linear Regression, all variables'] = [r_squared, mae, rmse, rae, rse]\nsummary_df",
      "execution_count": 10,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Linear Regression, all variables</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>R-squared</th>\n      <td>0.534771</td>\n    </tr>\n    <tr>\n      <th>Mean Absolute Error</th>\n      <td>3.064283</td>\n    </tr>\n    <tr>\n      <th>Root Mean Squared Error</th>\n      <td>3.472463</td>\n    </tr>\n    <tr>\n      <th>Relative Absolute Error</th>\n      <td>0.690154</td>\n    </tr>\n    <tr>\n      <th>Relative Squared Error</th>\n      <td>0.465229</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                         Linear Regression, all variables\nR-squared                                        0.534771\nMean Absolute Error                              3.064283\nRoot Mean Squared Error                          3.472463\nRelative Absolute Error                          0.690154\nRelative Squared Error                           0.465229"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Notice that the R-squared value for true vs. predicted `mpg` of the test set is much lower than it was for the training set. (Granted, our test set is not very large, so some fluctuation is expected.) This is indicative of model overfitting."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Linear Model with Feature Selection\n\nOne way to reduce overfitting is to remove some predictive features from the model. Ideally we would be able to examine many or all possible subsets of features and select the subset of features that gives the best performance, but that is usually impractical due to the large number of possible subsets. A common alternative is to start from the full list of features and recursively remove one that seems to be contributing least to the model's performance (i.e., the feature whose removal has the least negative/most positive effect on model performance). This process is called recursive feature elimination (RFE).\n\nRFE fits many models and compares their performance: it therefore requires both training and testing data. We would like to reserve the test dataset we created earlier to fairly compare all models, so RFE will need to set aside some records in the `X_train`/`y_train` dataset for its own round of testing. Fortunately, this is easily done with `scikit-learn`'s cross-validation functionality:"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFECV\nimport seaborn as sns\n\n# scale each feature to zero mean and unit variance\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\n\n# recursive feature elimination with cross validation, using r-squared score as metric\nlm = LinearRegression()  # using a linear model as before\nrfecv = RFECV(estimator=lm, step=1, cv=5) \nrfecv.fit(X_scaled, y_train)\n\n# print the optimal number of features\nprint('Optimal number of features: {}'.format(rfecv.n_features_))\n\n# save the selected features\nprint('Features selected: {}'.format(', '.join(np.array(feature_names)[rfecv.support_].tolist())))\n\n# get the feature elimination order\nranked_features, _ = zip(*sorted(zip(feature_names, rfecv.ranking_.tolist()),\n                                 key=lambda x: x[1],\n                                 reverse=True))\nprint('Suggested order of feature removal: {}'.format(', '.join(ranked_features)))\n\n# plot number of features vs. scores\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(8, 4))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Score\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/nbuser/anaconda2_410/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Optimal number of features: 1\nFeatures selected: wt\nSuggested order of feature removal: gear, vs, drat, cyl, carb, hp, disp, am, qsec, wt\n"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAF+CAYAAACbJTy+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyLXua8dPo0sAAAAASUVORK5CYII=\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fe04033dd10>"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The plot shows that the performance of the model (on the cross-validation testing set) tends to improve as we reduce the number of features in the model. As expected, weight and presence of an automatic transmission are among the features which would be removed last (since they are relevant for predicting gas mileage), whereas the number of forward gears is not so relevant.\n\nWe can now fit a linear model using only the selected features, and assess its performance on the test set:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train_subset = X_train[:, rfecv.support_]\nlm2 = LinearRegression()\nlm2.fit(X_train_subset, y_train)\n\nX_test_part = X_test[:, rfecv.support_]\npredicted = lm2.predict(X_test_part)\n\nr_squared = r2_score(y_test, predicted)\nmae = np.mean(abs(predicted - y_test))\nrmse = np.sqrt(np.mean((predicted - y_test)**2))\nrae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\nrse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n\nsummary_df['Linear Regression, selected variables'] = [r_squared, mae, rmse, rae, rse]\nsummary_df",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Linear Regression, all variables</th>\n      <th>Linear Regression, selected variables</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>R-squared</th>\n      <td>0.534771</td>\n      <td>0.809249</td>\n    </tr>\n    <tr>\n      <th>Mean Absolute Error</th>\n      <td>3.064283</td>\n      <td>1.756430</td>\n    </tr>\n    <tr>\n      <th>Root Mean Squared Error</th>\n      <td>3.472463</td>\n      <td>2.223504</td>\n    </tr>\n    <tr>\n      <th>Relative Absolute Error</th>\n      <td>0.690154</td>\n      <td>0.395592</td>\n    </tr>\n    <tr>\n      <th>Relative Squared Error</th>\n      <td>0.465229</td>\n      <td>0.190751</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                         Linear Regression, all variables  \\\nR-squared                                        0.534771   \nMean Absolute Error                              3.064283   \nRoot Mean Squared Error                          3.472463   \nRelative Absolute Error                          0.690154   \nRelative Squared Error                           0.465229   \n\n                         Linear Regression, selected variables  \nR-squared                                             0.809249  \nMean Absolute Error                                   1.756430  \nRoot Mean Squared Error                               2.223504  \nRelative Absolute Error                               0.395592  \nRelative Squared Error                                0.190751  "
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The model's performance on the withheld test set improved (by all metrics) after the majority of features were removed."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Gradient Boosting Machine Regression Model\n\nBefore fitting the gradient boosting model, we need to estimate some parameters and we'll do this using cross-validation along with grid search. The following code box may take some time to run:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.grid_search import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom time import time\n\n# We will try all combinations of these possible parameter values\ntuned_params = {'n_estimators': [5000, 10000], \n                'max_depth': [2,4], \n                'min_samples_split': [1, 2],\n                'learning_rate': [0.001, 0.01]}\ngscv = GridSearchCV(GradientBoostingRegressor(loss = 'ls', random_state=0), \n                    tuned_params, cv=5, scoring='mean_squared_error')\n\n# th\nstart = time()\ngscv.fit(X_train, y_train)\n\nprint('The grid cross validation lasted {:0.1f} seconds'.format(time() - start))\nprint('Best parameters set found on development set:\\n\\t{}'.format(\n        ', '.join(['{}: {}'.format(i,j) for i,j in gscv.best_params_.items()])))\nprint('Grid scores on development set:')\nfor params, mean_score, scores in gscv.grid_scores_:\n    print('\\t{:0.2f} (+/- {:0.2f}) for {}'.format(mean_score,\n                                      scores.std() * 2,\n                                      ', '.join(['{}: {}'.format(i, j) for i, j in params.items()])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We'll fit the GBM model with the parameters that gave the best performance:"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# fit model with the best set of parameter values\nparams = gscv.best_params_\nparams['random_state'] = 123\nparams['loss'] = 'ls'\ngbm = GradientBoostingRegressor(**params)\n\ngbm.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we can check the model's performance on the test data:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "predicted = gbm.predict(X_test)\n\nr_squared = r2_score(y_test, predicted)\nmae = np.mean(abs(predicted - y_test))\nrmse = np.sqrt(np.mean((predicted - y_test)**2))\nrae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\nrse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n\nsummary_df['Gradient Boosted Machine Regression'] = [r_squared, mae, rmse, rae, rse]\nsummary_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The plot below shows the feature importances:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# plot variable importance\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfeature_importance = gbm.feature_importances_\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\nsorted_idx = np.argsort(feature_importance)[::-1]\n\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(10, 6))\nindex = np.arange(len(feature_names))\nbar_width = 0.5\nplt.bar(index, feature_importance[sorted_idx], color='black', alpha=0.5)\nplt.xlabel('features')\nplt.ylabel('importance')\nplt.title('Feature importance')\nplt.xticks(index + bar_width, np.array(feature_names)[sorted_idx])\nplt.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Some features which were eliminated later by RFE (like `am`) have low feature importance in the GBM model.\n\nLet's assess whether our GBM model's performance is likely to be limited by the number of estimators used:"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# plot deviance for training set and test set\ntest_score = np.zeros(params['n_estimators'])\n\nfor j, y_pred in enumerate(gbm.staged_decision_function(X_test)):\n    test_score[j] = gbm.loss_(y_test, y_pred)\n\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(10, 6))\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, gbm.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Number of estimators')\nplt.ylabel('Deviance')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The plot above demonstrates that the loss function plateaus well before we reach the total number of estimators used by our model. We could likely get away with using fewer estimators for a speed improvement."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Conclusion\nThe following table compares the performance of the three models. Variable selection using RFE improved the performance of the linear regression model by all metrics. The GBM model performed comparably to linear regression with variable selection. (We will avoid reading too deeply into the differences in metrics, because the test dataset is so small.)"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "summary_df",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}